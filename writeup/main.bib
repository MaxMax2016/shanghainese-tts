@misc{erengolgeCoquiTTS2023,
  title = {Coqui {{TTS}}},
  author = {Eren, G{\"o}lge and Team, The Coqui TTS},
  year = {2023},
  month = may,
  doi = {10.5281/ZENODO.7940152},
  urldate = {2023-06-02},
  abstract = {A deep learning toolkit for Text-to-Speech, battle-tested in research and production},
  copyright = {Mozilla Public License 2.0, Open Access},
  howpublished = {Zenodo},
  keywords = {artificial intelligence,deep learning,machine learning,text to speech,TTS},
  timestamp = {2023-06-03T02:38:06Z}
}

@misc{junyiJieba2023,
  title = {Jieba},
  author = {Junyi, Sun},
  year = {2023},
  month = jun,
  urldate = {2023-06-03},
  abstract = {结巴中文分词},
  copyright = {MIT},
  timestamp = {2023-06-03T03:22:54Z}
}

@article{kimConditionalVariationalAutoencoder2021,
  title = {Conditional {{Variational Autoencoder}} with {{Adversarial Learning}} for {{End-to-End Text-to-Speech}}},
  author = {Kim, Jaehyeon and Kong, Jungil and Son, Juhee},
  year = {2021},
  publisher = {{arXiv}},
  doi = {10.48550/ARXIV.2106.06103},
  urldate = {2023-06-02},
  abstract = {Several recent end-to-end text-to-speech (TTS) models enabling single-stage training and parallel sampling have been proposed, but their sample quality does not match that of two-stage TTS systems. In this work, we present a parallel end-to-end TTS method that generates more natural sounding audio than current two-stage models. Our method adopts variational inference augmented with normalizing flows and an adversarial training process, which improves the expressive power of generative modeling. We also propose a stochastic duration predictor to synthesize speech with diverse rhythms from input text. With the uncertainty modeling over latent variables and the stochastic duration predictor, our method expresses the natural one-to-many relationship in which a text input can be spoken in multiple ways with different pitches and rhythms. A subjective human evaluation (mean opinion score, or MOS) on the LJ Speech, a single speaker dataset, shows that our method outperforms the best publicly available TTS systems and achieves a MOS comparable to ground truth.},
  copyright = {arXiv.org perpetual, non-exclusive license},
  keywords = {Audio and Speech Processing (eess.AS),FOS: Computer and information sciences,{FOS: Electrical engineering, electronic engineering, information engineering},Sound (cs.SD)},
  timestamp = {2023-06-02T18:24:06Z}
}

@misc{kuoOpenChineseConvert2023,
  title = {{{OpenCC}} ({{Open Chinese Convert}} 開放中文轉換)},
  author = {Kuo, Carbo},
  year = {2023},
  month = jun,
  urldate = {2023-06-03},
  abstract = {Conversion between Traditional and Simplified Chinese},
  copyright = {Apache-2.0},
  keywords = {chinese-translation,simplified-chinese,traditional-chinese},
  timestamp = {2023-06-03T02:38:43Z}
}

@phdthesis{robertsAutosegmentalMetricalModelShanghainese2020,
  title = {An {{Autosegmental-Metrical Model}} of {{Shanghainese Tone}} and {{Intonation}}},
  author = {Roberts, Brice David},
  year = {2020},
  urldate = {2023-06-01},
  abstract = {This dissertation presents a model of Shanghainese lexical tone and intonation based in the Autosegmental-Metrical framework and develops an annotation system for prosodic events in the language, known as Shanghainese Tones and Break Indices Labeling, or Sh\_ToBI. Full-sentence phonetic data from 21 Shanghainese speakers (born 1937-1975) were analyzed. Instead of a syllable tone language with left-dominant sandhi, Shanghainese is analyzed here as a lexical pitch accent language, with three levels of phrasing above the syllable. The lowest level of phrasing is the accentual phrase, which is the domain of the three contrastive pitch accents, H*, L*+H, and L*. These pitch accents are paired with one of two AP-final boundary tones: La/L:a or LHa. La/L:a varies freely between a single low target (La) and a low plateau (L:a), and co-occurs with H* and L*+H. LHa is a sharp rising boundary tone which accompanies L*. AP boundary tones always accompany simple pitch accents (H* and L*), while they only appear after bi-tonal L*+H in APs longer than two syllables. AP-initial tone targets, H* and L*, are prominent and are always the local pitch maximum or minimum, respectively. Above the AP is the intermediate phrase (ip), identifiable only by its phrase-final segmental lengthening, following pitch reset, and a lack of following silence. The highest level is the intonational phrase (IP) marked with initial pitch range expansion, and one of three IP-final boundary tones (H\%, L\%, or toneless \%). H\% is used in particle-final yes/no questions, interacting variably with preceding tones. L\% is used in corrective or other emotionally marked statements, creating contours with preceding tones. \% is toneless, and is used in most questions and all unmarked statements. It is recognizable via segmental lengthening, pitch range compression, and a following silence. Beyond this re-analysis of Shanghainese tone and phrasing, the dissertation finds intonational differences between two kinds of focus (general narrow and corrective), and explores the application of tonal reduction (also called `right-dominant sandhi') to both monosyllabic and disyllabic APs. Finally, a break index system for labeling the perceived amount of juncture between syllables was developed.},
  langid = {english},
  school = {UCLA},
  timestamp = {2023-06-01T21:36:53Z},
  file = {Full Text PDF:/Users/edwardchen/Zotero/storage/GWWLB7LY/Roberts - 2020 - An Autosegmental-Metrical Model of Shanghainese To.pdf:application/pdf}
}

@inproceedings{zhangProsodicMandarinTexttoSpeech2019,
  title = {A {{Prosodic Mandarin Text-to-Speech System Based}} on {{Tacotron}}},
  booktitle = {2019 {{Asia-Pacific Signal}} and {{Information Processing Association Annual Summit}} and {{Conference}} ({{APSIPA ASC}})},
  author = {Zhang, Chuxiong and Zhang, Sheng and Zhong, Haibing},
  year = {2019},
  month = nov,
  pages = {165--169},
  publisher = {{IEEE}},
  address = {{Lanzhou, China}},
  doi = {10.1109/APSIPAASC47483.2019.9023283},
  urldate = {2023-06-02},
  isbn = {978-1-72813-248-8},
  timestamp = {2023-06-02T18:20:01Z}
}
