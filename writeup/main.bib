@article{bezosCustomizingListsEnumitem,
  title = {Customizing Lists with the Enumitem Package},
  author = {Bezos, Javier},
  langid = {english},
  timestamp = {2023-06-06T01:40:49Z},
  file = {Bezos - Customizing lists with the enumitem package.pdf:/Users/edwardchen/Zotero/storage/SKSWDA5F/Bezos - Customizing lists with the enumitem package.pdf:application/pdf}
}

@inproceedings{cardosoEvaluatingTexttospeechSynthesizers2015,
  title = {Evaluating Text-to-Speech Synthesizers},
  booktitle = {Critical {{CALL}} \textendash{} {{Proceedings}} of the 2015 {{EUROCALL Conference}}, {{Padova}}, {{Italy}}},
  author = {Cardoso, Walcir and Smith, George and Garcia Fuentes, Cesar},
  year = {2015},
  month = dec,
  pages = {108--113},
  publisher = {{Research-publishing.net}},
  doi = {10.14705/rpnet.2015.000318},
  urldate = {2023-06-03},
  isbn = {978-1-908416-29-2},
  timestamp = {2023-06-03T19:55:38Z}
}

@misc{chenRimeIPAZaonhegho2020,
  title = {Rime {{IPA Zaonhegho}}},
  author = {Chen, Yuanhao},
  year = {2020},
  month = oct,
  doi = {10.5281/zenodo.8003366},
  urldate = {2023-06-04},
  abstract = {使用吳語協會式拼音輸入上海話IPA},
  howpublished = {Zenodo},
  timestamp = {2023-06-04T16:25:09Z}
}

@misc{cosmos-breakCosmosBreakAsr2023,
  title = {Shanghainese {{ASR}}},
  author = {{Cosmos-Break}},
  year = {2023},
  month = apr,
  url = {https://github.com/Cosmos-Break/asr},
  urldate = {2023-06-06},
  abstract = {沪语（上海话）ASR（语音识别）模型},
  keywords = {asr,dialect,shanghai},
  timestamp = {2023-06-06T03:27:13Z}
}

@misc{erengolgeCoquiTTS2023,
  title = {Coqui {{TTS}}},
  author = {Eren, G{\"o}lge and Team, The Coqui TTS},
  year = {2023},
  month = may,
  doi = {10.5281/ZENODO.7940152},
  urldate = {2023-06-02},
  abstract = {A deep learning toolkit for Text-to-Speech, battle-tested in research and production},
  copyright = {Mozilla Public License 2.0, Open Access},
  howpublished = {Zenodo},
  keywords = {artificial intelligence,deep learning,machine learning,text to speech,TTS},
  timestamp = {2023-06-03T18:41:20Z}
}

@phdthesis{gillilandLanguageAttitudesIdeologies2006,
  title = {Language {{Attitudes}} and {{Ideologies}} in {{Shanghai}}, {{China}}},
  author = {Gilliland, Joshua},
  year = {2006},
  url = {https://etd.ohiolink.edu/apexprod/rws_olink/r/1501/10?clear=10&p10_accession_num=osu1391600649},
  urldate = {2023-06-03},
  langid = {english},
  school = {The Ohio State University},
  timestamp = {2023-06-03T19:10:44Z},
  file = {Full Text PDF:/Users/edwardchen/Zotero/storage/X784B3EE/Gilliland - 2006 - Language Attitudes and Ideologies in Shanghai, Chi.pdf:application/pdf}
}

@misc{junyiJieba2023,
  title = {Jieba},
  author = {Sun, Junyi},
  year = {2023},
  month = jun,
  url = {https://github.com/fxsjy/jieba},
  urldate = {2023-06-03},
  abstract = {结巴中文分词},
  copyright = {MIT},
  timestamp = {2023-06-06T06:18:55Z}
}

@article{kimConditionalVariationalAutoencoder2021,
  title = {Conditional {{Variational Autoencoder}} with {{Adversarial Learning}} for {{End-to-End Text-to-Speech}}},
  author = {Kim, Jaehyeon and Kong, Jungil and Son, Juhee},
  year = {2021},
  publisher = {{arXiv}},
  doi = {10.48550/ARXIV.2106.06103},
  urldate = {2023-06-02},
  abstract = {Several recent end-to-end text-to-speech (TTS) models enabling single-stage training and parallel sampling have been proposed, but their sample quality does not match that of two-stage TTS systems. In this work, we present a parallel end-to-end TTS method that generates more natural sounding audio than current two-stage models. Our method adopts variational inference augmented with normalizing flows and an adversarial training process, which improves the expressive power of generative modeling. We also propose a stochastic duration predictor to synthesize speech with diverse rhythms from input text. With the uncertainty modeling over latent variables and the stochastic duration predictor, our method expresses the natural one-to-many relationship in which a text input can be spoken in multiple ways with different pitches and rhythms. A subjective human evaluation (mean opinion score, or MOS) on the LJ Speech, a single speaker dataset, shows that our method outperforms the best publicly available TTS systems and achieves a MOS comparable to ground truth.},
  copyright = {arXiv.org perpetual, non-exclusive license},
  keywords = {Audio and Speech Processing (eess.AS),FOS: Computer and information sciences,{FOS: Electrical engineering, electronic engineering, information engineering},Sound (cs.SD)},
  timestamp = {2023-06-02T18:24:06Z}
}

@misc{kimGlowTTSGenerativeFlow2020,
  title = {Glow-{{TTS}}: {{A Generative Flow}} for {{Text-to-Speech}} via {{Monotonic Alignment Search}}},
  shorttitle = {Glow-{{TTS}}},
  author = {Kim, Jaehyeon and Kim, Sungwon and Kong, Jungil and Yoon, Sungroh},
  year = {2020},
  month = oct,
  number = {arXiv:2005.11129},
  eprint = {2005.11129},
  primaryclass = {cs, eess},
  publisher = {{arXiv}},
  url = {http://arxiv.org/abs/2005.11129},
  urldate = {2023-06-04},
  abstract = {Recently, text-to-speech (TTS) models such as FastSpeech and ParaNet have been proposed to generate mel-spectrograms from text in parallel. Despite the advantage, the parallel TTS models cannot be trained without guidance from autoregressive TTS models as their external aligners. In this work, we propose Glow-TTS, a flow-based generative model for parallel TTS that does not require any external aligner. By combining the properties of flows and dynamic programming, the proposed model searches for the most probable monotonic alignment between text and the latent representation of speech on its own. We demonstrate that enforcing hard monotonic alignments enables robust TTS, which generalizes to long utterances, and employing generative flows enables fast, diverse, and controllable speech synthesis. Glow-TTS obtains an order-of-magnitude speed-up over the autoregressive model, Tacotron 2, at synthesis with comparable speech quality. We further show that our model can be easily extended to a multi-speaker setting.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Sound,Electrical Engineering and Systems Science - Audio and Speech Processing},
  timestamp = {2023-06-04T03:24:33Z},
  file = {arXiv Fulltext PDF:/Users/edwardchen/Zotero/storage/XQI3J2X6/Kim et al. - 2020 - Glow-TTS A Generative Flow for Text-to-Speech via.pdf:application/pdf;arXiv.org Snapshot:/Users/edwardchen/Zotero/storage/HEMRU6DB/2005.html:text/html}
}

@inproceedings{kuangToneRepresentationTone2019,
  title = {Tone {{Representation}} and {{Tone Processing}} in {{Shanghainese}}},
  booktitle = {Proceedings of the 19th {{International Congress}} of {{Phonetic Sciences}}},
  author = {Kuang, Jianjing and Tian, Jiapeng},
  year = {2019},
  address = {{Melbourne, Australia}},
  url = {https://www.semanticscholar.org/paper/TONE-REPRESENTATION-AND-TONE-PROCESSING-IN-Kuang-Tian/8d39379d2d3e63b2c07833b99cc1abe67d1ecfd7},
  urldate = {2023-06-03},
  abstract = {In Shanghainese, it has been assumed that contrastive sandhi tones at the word level are derived from base tones at the syllable level by a spreading rule. Does this mean that speakers have to access syllable tones before computing sandhi patterns? By examining the production latencies of a speeded production experiment, we show that Shanghainese speakers produce sandhi tones fairly fast, but are much slower in producing syllable tones. This result suggests that Shanghainese speakers in fact access sandhi tones directly without referring to base tones. By contrast, as the control group, Mandarin speakers produce words and syllables equally fast. In light of these findings, we will discuss how Shanghainese speakers represent and process the tonal contrasts at both syllable and word levels.},
  timestamp = {2023-06-03T22:11:29Z},
  file = {Full Text PDF:/Users/edwardchen/Zotero/storage/RQ4GSCHW/Kuang and Tian - 2019 - TONE REPRESENTATION AND TONE PROCESSING IN SHANGHA.pdf:application/pdf}
}

@misc{kuoOpenChineseConvert2023,
  title = {{{OpenCC}} ({{Open Chinese Convert}} 開放中文轉換)},
  author = {Kuo, Carbo},
  year = {2023},
  month = jun,
  url = {https://github.com/BYVoid/OpenCC},
  urldate = {2023-06-03},
  abstract = {Conversion between Traditional and Simplified Chinese},
  copyright = {Apache-2.0},
  keywords = {chinese-translation,simplified-chinese,traditional-chinese},
  timestamp = {2023-06-03T02:38:43Z}
}

@book{qianShanghaiFangYan2007,
  title = {Shanghai {{Fangyan}} ({{Shanghainese}})},
  author = {Qian, Nairong},
  year = {2007},
  series = {Haipai {{Wenhua Congshu}}},
  edition = {First},
  publisher = {{Wenhui Press}},
  address = {{Shanghai}},
  isbn = {978-7-80741-223-6},
  lccn = {PL1940.S53 Q257 2007},
  keywords = {China Shanghai,Chinese language,Dialects,Wu dialects},
  annotation = {OCLC: ocn185027801},
  timestamp = {2023-06-04T03:00:20Z}
}

@misc{Qieyunpython2022,
  title = {Qieyun-Python},
  author = {Mikazuki, Ayaka},
  year = {2022},
  month = oct,
  url = {https://github.com/nk2028/qieyun-python},
  urldate = {2023-06-04},
  abstract = {A Python library for the Qieyun phonological system},
  copyright = {CC0-1.0},
  howpublished = {nk2028},
  keywords = {historical-linguistics,middle-chinese,qieyun},
  timestamp = {2023-06-04T03:12:11Z}
}

@phdthesis{robertsAutosegmentalMetricalModelShanghainese2020,
  title = {An {{Autosegmental-Metrical Model}} of {{Shanghainese Tone}} and {{Intonation}}},
  author = {Roberts, Brice David},
  year = {2020},
  url = {https://escholarship.org/uc/item/5hm0n8b7},
  urldate = {2023-06-01},
  abstract = {This dissertation presents a model of Shanghainese lexical tone and intonation based in the Autosegmental-Metrical framework and develops an annotation system for prosodic events in the language, known as Shanghainese Tones and Break Indices Labeling, or Sh\_ToBI. Full-sentence phonetic data from 21 Shanghainese speakers (born 1937-1975) were analyzed. Instead of a syllable tone language with left-dominant sandhi, Shanghainese is analyzed here as a lexical pitch accent language, with three levels of phrasing above the syllable. The lowest level of phrasing is the accentual phrase, which is the domain of the three contrastive pitch accents, H*, L*+H, and L*. These pitch accents are paired with one of two AP-final boundary tones: La/L:a or LHa. La/L:a varies freely between a single low target (La) and a low plateau (L:a), and co-occurs with H* and L*+H. LHa is a sharp rising boundary tone which accompanies L*. AP boundary tones always accompany simple pitch accents (H* and L*), while they only appear after bi-tonal L*+H in APs longer than two syllables. AP-initial tone targets, H* and L*, are prominent and are always the local pitch maximum or minimum, respectively. Above the AP is the intermediate phrase (ip), identifiable only by its phrase-final segmental lengthening, following pitch reset, and a lack of following silence. The highest level is the intonational phrase (IP) marked with initial pitch range expansion, and one of three IP-final boundary tones (H\%, L\%, or toneless \%). H\% is used in particle-final yes/no questions, interacting variably with preceding tones. L\% is used in corrective or other emotionally marked statements, creating contours with preceding tones. \% is toneless, and is used in most questions and all unmarked statements. It is recognizable via segmental lengthening, pitch range compression, and a following silence. Beyond this re-analysis of Shanghainese tone and phrasing, the dissertation finds intonational differences between two kinds of focus (general narrow and corrective), and explores the application of tonal reduction (also called `right-dominant sandhi') to both monosyllabic and disyllabic APs. Finally, a break index system for labeling the perceived amount of juncture between syllables was developed.},
  langid = {english},
  school = {UCLA},
  timestamp = {2023-06-01T21:36:53Z},
  file = {Full Text PDF:/Users/edwardchen/Zotero/storage/GWWLB7LY/Roberts - 2020 - An Autosegmental-Metrical Model of Shanghainese To.pdf:application/pdf}
}

@article{villaIntegratingTechnologyMinority2002,
  title = {Integrating Technology into Minority Language Preservation and Teaching Efforts: {{An}} inside Job},
  shorttitle = {Integrating Technology into Minority Language Preservation and Teaching Efforts},
  author = {Villa, Daniel J.},
  year = {2002},
  month = may,
  journal = {Language Learning \& Technology},
  volume = {6},
  number = {2},
  publisher = {{University of Hawaii National Foreign Language Resource Center}},
  issn = {1094-3501},
  url = {http://dx.doi.org/10125/25163},
  urldate = {2023-06-03},
  langid = {english},
  timestamp = {2023-06-03T20:05:56Z},
  file = {Full Text PDF:/Users/edwardchen/Zotero/storage/63FUCMC7/Villa - 2002 - Integrating technology into minority language pres.pdf:application/pdf}
}

@misc{VoiceOver,
  title = {{{VoiceOver}}},
  author = {{Apple Inc.}},
  year = {2017},
  howpublished = {Apple Inc.},
  timestamp = {2023-06-03T20:07:53Z}
}

@article{wengSecondGenerationNew2023,
  title = {The Second Generation of ``{{New Shanghainese}}'': Their Language and Identity},
  shorttitle = {The Second Generation of ``{{New Shanghainese}}''},
  author = {Weng, Shihong},
  year = {2023},
  month = jan,
  journal = {San Diego Linguistic Papers},
  volume = {12},
  url = {https://escholarship.org/uc/item/2526g7ms},
  urldate = {2023-06-03},
  abstract = {Author(s): Weng, Shihong},
  langid = {english},
  timestamp = {2023-06-03T20:05:32Z},
  file = {Full Text PDF:/Users/edwardchen/Zotero/storage/UT3UF8FU/Weng - 2023 - The second generation of “New Shanghainese” their.pdf:application/pdf}
}

@misc{yuanhaochenRimeYahweZaonhe2022,
  title = {Rime {{Yahwe Zaonhe}}},
  author = {Chen, Yuanhao},
  year = {2022},
  month = jul,
  doi = {10.5281/ZENODO.8002073},
  urldate = {2023-06-03},
  abstract = {吳語協會式上海話輸入法/吴语协会式上海话输入法:以吳語協會式拼音爲基礎的 Rime 上海話輸入方案。},
  copyright = {Open Access},
  howpublished = {Zenodo},
  timestamp = {2023-06-03T18:49:25Z}
}

@inproceedings{zhangProsodicMandarinTexttoSpeech2019,
  title = {A {{Prosodic Mandarin Text-to-Speech System Based}} on {{Tacotron}}},
  booktitle = {2019 {{Asia-Pacific Signal}} and {{Information Processing Association Annual Summit}} and {{Conference}} ({{APSIPA ASC}})},
  author = {Zhang, Chuxiong and Zhang, Sheng and Zhong, Haibing},
  year = {2019},
  month = nov,
  pages = {165--169},
  publisher = {{IEEE}},
  address = {{Lanzhou, China}},
  doi = {10.1109/APSIPAASC47483.2019.9023283},
  urldate = {2023-06-02},
  isbn = {978-1-72813-248-8},
  timestamp = {2023-06-02T18:20:01Z}
}
